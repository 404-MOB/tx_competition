{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer#,TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from scipy import sparse\n",
    "import os\n",
    "#from gensim.models.word2vec import Word2Vec\n",
    "#import python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_feature=pd.read_csv('../data/adFeature.csv')\n",
    "user_feature=pd.read_csv('../data/userFeature/userFeature_1.csv')#29\n",
    "train=pd.read_csv('../data/train/train_1.csv')\n",
    "predict=pd.read_csv('../data/test1/test1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ad_feature=pd.read_csv('data/adFeature.csv')\n",
    "#user_feature = pd.read_csv('data/userFeature.csv')\n",
    "#train = pd.read_csv('data/train.csv')\n",
    "#predict = pd.read_csv('data/test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拼接数据（左联接），分one-hot特征和向量特征\n",
    "train.loc[train['label']==-1,'label']=0\n",
    "predict['label']=-1\n",
    "data=pd.concat([train,predict])\n",
    "data=pd.merge(data,ad_feature,on='aid',how='left')\n",
    "data=pd.merge(data,user_feature,on='uid',how='left')\n",
    "\n",
    "#data['ct'].fillna('21', inplace = True)\n",
    "#data['os'].fillna('1', inplace = True)\n",
    "#data['carrier'].fillna('1', inplace = True)\n",
    "#data['house'].fillna('0', inplace = True)\n",
    "data=data.fillna('-1')\n",
    "\n",
    "one_hot_feature=['LBS','age','carrier','consumptionAbility','education','gender','house']\n",
    "vector_feature=['appIdAction','appIdInstall','os','ct','marriageStatus','interest1','interest2','interest3','interest4','interest5','kw1','kw2','kw3','topic1','topic2','topic3']\n",
    "#LabelEncoder将各种标签分配一个可数的连续编号\n",
    "for feature in one_hot_feature:\n",
    "    try:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature].apply(int))\n",
    "    except:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "        \n",
    "train=data[data.label!=-1]\n",
    "train_y=train.pop('label')\n",
    "\n",
    "test=data[data.label==-1]\n",
    "res=test[['aid','uid']]\n",
    "test=test.drop('label',axis=1)\n",
    "\n",
    "train_x=train[['advertiserId','campaignId', 'creativeId','creativeSize','adCategoryId', 'productId', 'productType']]\n",
    "test_x=test[['advertiserId','campaignId', 'creativeId','creativeSize','adCategoryId', 'productId', 'productType']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot prepared !\n"
     ]
    }
   ],
   "source": [
    "#one-hot特征reshape\n",
    "enc = OneHotEncoder()\n",
    "for feature in one_hot_feature:\n",
    "    enc.fit(data[feature].values.reshape(-1, 1))\n",
    "    train_a=enc.transform(train[feature].values.reshape(-1, 1))\n",
    "    test_a = enc.transform(test[feature].values.reshape(-1, 1))\n",
    "    train_x= sparse.hstack((train_x, train_a))\n",
    "    test_x = sparse.hstack((test_x, test_a))\n",
    "print('one-hot prepared !')\n",
    "del train_a\n",
    "del test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv prepared !\n"
     ]
    }
   ],
   "source": [
    "##向量特征reshape\n",
    "cv=CountVectorizer(ngram_range=(1, 2),token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "for feature in vector_feature:\n",
    "    cv.fit(data[feature])\n",
    "    train_a = cv.transform(train[feature])\n",
    "    test_a = cv.transform(test[feature])\n",
    "    train_x = sparse.hstack((train_x, train_a))\n",
    "    test_x = sparse.hstack((test_x, test_a))\n",
    "print('cv prepared !')\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "#print(cv.vocabulary_) \n",
    "\n",
    "del train_a\n",
    "del test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#然后直接甩给LightGBM。。\n",
    "def LGB_test(train_x,train_y,test_x,test_y):\n",
    "    from multiprocessing import cpu_count\n",
    "    print(\"LGB test\")\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,zero_as_missing=True,\n",
    "        max_depth=-1, n_estimators=500, objective='binary',\n",
    "        subsample=0.9, colsample_bytree=0.8, subsample_freq=1,\n",
    "        learning_rate=0.1, min_child_weight=150, random_state=2018,n_jobs=cpu_count()-1\n",
    "    )\n",
    "    clf.fit(train_x, train_y,eval_set=[(train_x, train_y),(test_x,test_y)],eval_metric='auc',early_stopping_rounds=100)\n",
    "    # print(clf.feature_importances_)\n",
    "    return clf,clf.best_score_[ 'valid_1']['auc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB test\n",
      "[1]\tvalid_0's auc: 0.501845\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's auc: 0.502672\n",
      "[3]\tvalid_0's auc: 0.502672\n",
      "[4]\tvalid_0's auc: 0.502673\n",
      "[5]\tvalid_0's auc: 0.508641\n",
      "[6]\tvalid_0's auc: 0.510836\n",
      "[7]\tvalid_0's auc: 0.51342\n",
      "[8]\tvalid_0's auc: 0.514126\n",
      "[9]\tvalid_0's auc: 0.514142\n",
      "[10]\tvalid_0's auc: 0.516599\n",
      "[11]\tvalid_0's auc: 0.518737\n",
      "[12]\tvalid_0's auc: 0.519551\n",
      "[13]\tvalid_0's auc: 0.52233\n",
      "[14]\tvalid_0's auc: 0.524581\n",
      "[15]\tvalid_0's auc: 0.525526\n",
      "[16]\tvalid_0's auc: 0.526455\n",
      "[17]\tvalid_0's auc: 0.526836\n",
      "[18]\tvalid_0's auc: 0.52785\n",
      "[19]\tvalid_0's auc: 0.529047\n",
      "[20]\tvalid_0's auc: 0.529674\n",
      "[21]\tvalid_0's auc: 0.530778\n",
      "[22]\tvalid_0's auc: 0.531108\n",
      "[23]\tvalid_0's auc: 0.531598\n",
      "[24]\tvalid_0's auc: 0.532219\n",
      "[25]\tvalid_0's auc: 0.53236\n",
      "[26]\tvalid_0's auc: 0.532727\n",
      "[27]\tvalid_0's auc: 0.533179\n",
      "[28]\tvalid_0's auc: 0.533281\n",
      "[29]\tvalid_0's auc: 0.533518\n",
      "[30]\tvalid_0's auc: 0.533816\n",
      "[31]\tvalid_0's auc: 0.534356\n",
      "[32]\tvalid_0's auc: 0.534803\n",
      "[33]\tvalid_0's auc: 0.535235\n",
      "[34]\tvalid_0's auc: 0.535741\n",
      "[35]\tvalid_0's auc: 0.535986\n",
      "[36]\tvalid_0's auc: 0.535943\n",
      "[37]\tvalid_0's auc: 0.53604\n",
      "[38]\tvalid_0's auc: 0.536274\n",
      "[39]\tvalid_0's auc: 0.53636\n",
      "[40]\tvalid_0's auc: 0.536782\n",
      "[41]\tvalid_0's auc: 0.536808\n",
      "[42]\tvalid_0's auc: 0.536775\n",
      "[43]\tvalid_0's auc: 0.536963\n",
      "[44]\tvalid_0's auc: 0.537484\n",
      "[45]\tvalid_0's auc: 0.537589\n",
      "[46]\tvalid_0's auc: 0.537769\n",
      "[47]\tvalid_0's auc: 0.537991\n",
      "[48]\tvalid_0's auc: 0.537941\n",
      "[49]\tvalid_0's auc: 0.53795\n",
      "[50]\tvalid_0's auc: 0.53813\n",
      "[51]\tvalid_0's auc: 0.538295\n",
      "[52]\tvalid_0's auc: 0.53838\n",
      "[53]\tvalid_0's auc: 0.538528\n",
      "[54]\tvalid_0's auc: 0.538678\n",
      "[55]\tvalid_0's auc: 0.538877\n",
      "[56]\tvalid_0's auc: 0.53891\n",
      "[57]\tvalid_0's auc: 0.539092\n",
      "[58]\tvalid_0's auc: 0.539079\n",
      "[59]\tvalid_0's auc: 0.539179\n",
      "[60]\tvalid_0's auc: 0.539248\n",
      "[61]\tvalid_0's auc: 0.539283\n",
      "[62]\tvalid_0's auc: 0.539396\n",
      "[63]\tvalid_0's auc: 0.539377\n",
      "[64]\tvalid_0's auc: 0.539538\n",
      "[65]\tvalid_0's auc: 0.539715\n",
      "[66]\tvalid_0's auc: 0.539797\n",
      "[67]\tvalid_0's auc: 0.539911\n",
      "[68]\tvalid_0's auc: 0.539977\n",
      "[69]\tvalid_0's auc: 0.539971\n",
      "[70]\tvalid_0's auc: 0.540116\n",
      "[71]\tvalid_0's auc: 0.540104\n",
      "[72]\tvalid_0's auc: 0.540129\n",
      "[73]\tvalid_0's auc: 0.540114\n",
      "[74]\tvalid_0's auc: 0.540081\n",
      "[75]\tvalid_0's auc: 0.540112\n",
      "[76]\tvalid_0's auc: 0.540124\n",
      "[77]\tvalid_0's auc: 0.540221\n",
      "[78]\tvalid_0's auc: 0.540325\n",
      "[79]\tvalid_0's auc: 0.540412\n",
      "[80]\tvalid_0's auc: 0.540474\n",
      "[81]\tvalid_0's auc: 0.54051\n",
      "[82]\tvalid_0's auc: 0.540641\n",
      "[83]\tvalid_0's auc: 0.540671\n",
      "[84]\tvalid_0's auc: 0.540712\n",
      "[85]\tvalid_0's auc: 0.540799\n",
      "[86]\tvalid_0's auc: 0.54079\n",
      "[87]\tvalid_0's auc: 0.540807\n",
      "[88]\tvalid_0's auc: 0.540871\n",
      "[89]\tvalid_0's auc: 0.540841\n",
      "[90]\tvalid_0's auc: 0.540856\n",
      "[91]\tvalid_0's auc: 0.540869\n",
      "[92]\tvalid_0's auc: 0.540926\n",
      "[93]\tvalid_0's auc: 0.540956\n",
      "[94]\tvalid_0's auc: 0.541096\n",
      "[95]\tvalid_0's auc: 0.541072\n",
      "[96]\tvalid_0's auc: 0.541204\n",
      "[97]\tvalid_0's auc: 0.541164\n",
      "[98]\tvalid_0's auc: 0.541174\n",
      "[99]\tvalid_0's auc: 0.541207\n",
      "[100]\tvalid_0's auc: 0.541286\n",
      "[101]\tvalid_0's auc: 0.541284\n",
      "[102]\tvalid_0's auc: 0.54126\n",
      "[103]\tvalid_0's auc: 0.54128\n",
      "[104]\tvalid_0's auc: 0.541271\n",
      "[105]\tvalid_0's auc: 0.541214\n",
      "[106]\tvalid_0's auc: 0.541245\n",
      "[107]\tvalid_0's auc: 0.541318\n",
      "[108]\tvalid_0's auc: 0.541353\n",
      "[109]\tvalid_0's auc: 0.54143\n",
      "[110]\tvalid_0's auc: 0.541494\n",
      "[111]\tvalid_0's auc: 0.541554\n",
      "[112]\tvalid_0's auc: 0.541549\n",
      "[113]\tvalid_0's auc: 0.541565\n",
      "[114]\tvalid_0's auc: 0.541578\n",
      "[115]\tvalid_0's auc: 0.541631\n",
      "[116]\tvalid_0's auc: 0.541627\n",
      "[117]\tvalid_0's auc: 0.541617\n",
      "[118]\tvalid_0's auc: 0.541679\n",
      "[119]\tvalid_0's auc: 0.541644\n",
      "[120]\tvalid_0's auc: 0.541652\n",
      "[121]\tvalid_0's auc: 0.541761\n",
      "[122]\tvalid_0's auc: 0.541806\n",
      "[123]\tvalid_0's auc: 0.54179\n",
      "[124]\tvalid_0's auc: 0.541786\n",
      "[125]\tvalid_0's auc: 0.541765\n",
      "[126]\tvalid_0's auc: 0.541783\n",
      "[127]\tvalid_0's auc: 0.541787\n",
      "[128]\tvalid_0's auc: 0.541808\n",
      "[129]\tvalid_0's auc: 0.541829\n",
      "[130]\tvalid_0's auc: 0.541815\n",
      "[131]\tvalid_0's auc: 0.541836\n",
      "[132]\tvalid_0's auc: 0.54182\n",
      "[133]\tvalid_0's auc: 0.541813\n",
      "[134]\tvalid_0's auc: 0.541894\n",
      "[135]\tvalid_0's auc: 0.541912\n",
      "[136]\tvalid_0's auc: 0.541966\n",
      "[137]\tvalid_0's auc: 0.542004\n",
      "[138]\tvalid_0's auc: 0.542037\n",
      "[139]\tvalid_0's auc: 0.542107\n",
      "[140]\tvalid_0's auc: 0.542146\n",
      "[141]\tvalid_0's auc: 0.542212\n",
      "[142]\tvalid_0's auc: 0.542234\n",
      "[143]\tvalid_0's auc: 0.542273\n",
      "[144]\tvalid_0's auc: 0.542265\n",
      "[145]\tvalid_0's auc: 0.542296\n",
      "[146]\tvalid_0's auc: 0.542243\n",
      "[147]\tvalid_0's auc: 0.542266\n",
      "[148]\tvalid_0's auc: 0.542349\n",
      "[149]\tvalid_0's auc: 0.542348\n",
      "[150]\tvalid_0's auc: 0.542328\n",
      "[151]\tvalid_0's auc: 0.542381\n",
      "[152]\tvalid_0's auc: 0.542378\n",
      "[153]\tvalid_0's auc: 0.542337\n",
      "[154]\tvalid_0's auc: 0.542357\n",
      "[155]\tvalid_0's auc: 0.542413\n",
      "[156]\tvalid_0's auc: 0.542372\n",
      "[157]\tvalid_0's auc: 0.542332\n",
      "[158]\tvalid_0's auc: 0.542365\n",
      "[159]\tvalid_0's auc: 0.542354\n",
      "[160]\tvalid_0's auc: 0.542389\n",
      "[161]\tvalid_0's auc: 0.542428\n",
      "[162]\tvalid_0's auc: 0.542372\n",
      "[163]\tvalid_0's auc: 0.54241\n",
      "[164]\tvalid_0's auc: 0.542448\n",
      "[165]\tvalid_0's auc: 0.542553\n",
      "[166]\tvalid_0's auc: 0.542587\n",
      "[167]\tvalid_0's auc: 0.542646\n",
      "[168]\tvalid_0's auc: 0.54267\n",
      "[169]\tvalid_0's auc: 0.542692\n",
      "[170]\tvalid_0's auc: 0.542699\n",
      "[171]\tvalid_0's auc: 0.542745\n",
      "[172]\tvalid_0's auc: 0.542753\n",
      "[173]\tvalid_0's auc: 0.542808\n",
      "[174]\tvalid_0's auc: 0.542845\n",
      "[175]\tvalid_0's auc: 0.54282\n",
      "[176]\tvalid_0's auc: 0.542846\n",
      "[177]\tvalid_0's auc: 0.542853\n",
      "[178]\tvalid_0's auc: 0.54292\n",
      "[179]\tvalid_0's auc: 0.542912\n",
      "[180]\tvalid_0's auc: 0.542944\n",
      "[181]\tvalid_0's auc: 0.542933\n",
      "[182]\tvalid_0's auc: 0.542929\n",
      "[183]\tvalid_0's auc: 0.542943\n",
      "[184]\tvalid_0's auc: 0.542987\n",
      "[185]\tvalid_0's auc: 0.543027\n",
      "[186]\tvalid_0's auc: 0.543015\n",
      "[187]\tvalid_0's auc: 0.543056\n",
      "[188]\tvalid_0's auc: 0.543089\n",
      "[189]\tvalid_0's auc: 0.543105\n",
      "[190]\tvalid_0's auc: 0.543141\n",
      "[191]\tvalid_0's auc: 0.543158\n",
      "[192]\tvalid_0's auc: 0.543247\n",
      "[193]\tvalid_0's auc: 0.543258\n",
      "[194]\tvalid_0's auc: 0.543306\n",
      "[195]\tvalid_0's auc: 0.543347\n",
      "[196]\tvalid_0's auc: 0.543371\n",
      "[197]\tvalid_0's auc: 0.543386\n",
      "[198]\tvalid_0's auc: 0.543411\n",
      "[199]\tvalid_0's auc: 0.543428\n",
      "[200]\tvalid_0's auc: 0.543441\n",
      "[201]\tvalid_0's auc: 0.543458\n",
      "[202]\tvalid_0's auc: 0.543467\n",
      "[203]\tvalid_0's auc: 0.543515\n",
      "[204]\tvalid_0's auc: 0.543548\n",
      "[205]\tvalid_0's auc: 0.543591\n",
      "[206]\tvalid_0's auc: 0.543535\n",
      "[207]\tvalid_0's auc: 0.54352\n",
      "[208]\tvalid_0's auc: 0.543531\n",
      "[209]\tvalid_0's auc: 0.543634\n",
      "[210]\tvalid_0's auc: 0.543691\n",
      "[211]\tvalid_0's auc: 0.54375\n",
      "[212]\tvalid_0's auc: 0.543767\n",
      "[213]\tvalid_0's auc: 0.54382\n",
      "[214]\tvalid_0's auc: 0.543892\n",
      "[215]\tvalid_0's auc: 0.543943\n",
      "[216]\tvalid_0's auc: 0.543925\n",
      "[217]\tvalid_0's auc: 0.543948\n",
      "[218]\tvalid_0's auc: 0.543971\n",
      "[219]\tvalid_0's auc: 0.543977\n",
      "[220]\tvalid_0's auc: 0.544012\n",
      "[221]\tvalid_0's auc: 0.544029\n",
      "[222]\tvalid_0's auc: 0.544068\n",
      "[223]\tvalid_0's auc: 0.544082\n",
      "[224]\tvalid_0's auc: 0.54414\n",
      "[225]\tvalid_0's auc: 0.544145\n",
      "[226]\tvalid_0's auc: 0.544139\n",
      "[227]\tvalid_0's auc: 0.54415\n",
      "[228]\tvalid_0's auc: 0.54418\n",
      "[229]\tvalid_0's auc: 0.54417\n",
      "[230]\tvalid_0's auc: 0.54417\n",
      "[231]\tvalid_0's auc: 0.544226\n",
      "[232]\tvalid_0's auc: 0.544323\n",
      "[233]\tvalid_0's auc: 0.544361\n",
      "[234]\tvalid_0's auc: 0.544408\n",
      "[235]\tvalid_0's auc: 0.544377\n",
      "[236]\tvalid_0's auc: 0.544481\n",
      "[237]\tvalid_0's auc: 0.544531\n",
      "[238]\tvalid_0's auc: 0.544489\n",
      "[239]\tvalid_0's auc: 0.544508\n",
      "[240]\tvalid_0's auc: 0.544439\n",
      "[241]\tvalid_0's auc: 0.544438\n",
      "[242]\tvalid_0's auc: 0.5445\n",
      "[243]\tvalid_0's auc: 0.544487\n",
      "[244]\tvalid_0's auc: 0.544482\n",
      "[245]\tvalid_0's auc: 0.544481\n",
      "[246]\tvalid_0's auc: 0.544484\n",
      "[247]\tvalid_0's auc: 0.544495\n",
      "[248]\tvalid_0's auc: 0.544545\n",
      "[249]\tvalid_0's auc: 0.544572\n",
      "[250]\tvalid_0's auc: 0.544618\n",
      "[251]\tvalid_0's auc: 0.544555\n",
      "[252]\tvalid_0's auc: 0.54456\n",
      "[253]\tvalid_0's auc: 0.5446\n",
      "[254]\tvalid_0's auc: 0.544601\n",
      "[255]\tvalid_0's auc: 0.544636\n",
      "[256]\tvalid_0's auc: 0.544629\n",
      "[257]\tvalid_0's auc: 0.54465\n",
      "[258]\tvalid_0's auc: 0.54467\n",
      "[259]\tvalid_0's auc: 0.544707\n",
      "[260]\tvalid_0's auc: 0.544722\n",
      "[261]\tvalid_0's auc: 0.544727\n",
      "[262]\tvalid_0's auc: 0.544737\n",
      "[263]\tvalid_0's auc: 0.544815\n",
      "[264]\tvalid_0's auc: 0.544849\n",
      "[265]\tvalid_0's auc: 0.544817\n",
      "[266]\tvalid_0's auc: 0.54484\n",
      "[267]\tvalid_0's auc: 0.544859\n",
      "[268]\tvalid_0's auc: 0.544867\n",
      "[269]\tvalid_0's auc: 0.544851\n",
      "[270]\tvalid_0's auc: 0.544909\n",
      "[271]\tvalid_0's auc: 0.544921\n",
      "[272]\tvalid_0's auc: 0.544988\n",
      "[273]\tvalid_0's auc: 0.544955\n",
      "[274]\tvalid_0's auc: 0.544986\n",
      "[275]\tvalid_0's auc: 0.544999\n",
      "[276]\tvalid_0's auc: 0.544938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[277]\tvalid_0's auc: 0.545009\n",
      "[278]\tvalid_0's auc: 0.54501\n",
      "[279]\tvalid_0's auc: 0.545047\n",
      "[280]\tvalid_0's auc: 0.545058\n",
      "[281]\tvalid_0's auc: 0.545114\n",
      "[282]\tvalid_0's auc: 0.545104\n",
      "[283]\tvalid_0's auc: 0.545114\n",
      "[284]\tvalid_0's auc: 0.545092\n",
      "[285]\tvalid_0's auc: 0.545094\n",
      "[286]\tvalid_0's auc: 0.545116\n",
      "[287]\tvalid_0's auc: 0.545105\n",
      "[288]\tvalid_0's auc: 0.545139\n",
      "[289]\tvalid_0's auc: 0.545137\n",
      "[290]\tvalid_0's auc: 0.545131\n",
      "[291]\tvalid_0's auc: 0.54517\n",
      "[292]\tvalid_0's auc: 0.545213\n",
      "[293]\tvalid_0's auc: 0.545221\n",
      "[294]\tvalid_0's auc: 0.545218\n",
      "[295]\tvalid_0's auc: 0.545253\n",
      "[296]\tvalid_0's auc: 0.54528\n",
      "[297]\tvalid_0's auc: 0.545309\n",
      "[298]\tvalid_0's auc: 0.545287\n",
      "[299]\tvalid_0's auc: 0.545314\n",
      "[300]\tvalid_0's auc: 0.545279\n",
      "[301]\tvalid_0's auc: 0.545294\n",
      "[302]\tvalid_0's auc: 0.54529\n",
      "[303]\tvalid_0's auc: 0.545252\n",
      "[304]\tvalid_0's auc: 0.545308\n",
      "[305]\tvalid_0's auc: 0.545342\n",
      "[306]\tvalid_0's auc: 0.545369\n",
      "[307]\tvalid_0's auc: 0.54541\n",
      "[308]\tvalid_0's auc: 0.545396\n",
      "[309]\tvalid_0's auc: 0.54544\n",
      "[310]\tvalid_0's auc: 0.545486\n",
      "[311]\tvalid_0's auc: 0.545534\n",
      "[312]\tvalid_0's auc: 0.54556\n",
      "[313]\tvalid_0's auc: 0.545599\n",
      "[314]\tvalid_0's auc: 0.545589\n",
      "[315]\tvalid_0's auc: 0.545614\n",
      "[316]\tvalid_0's auc: 0.545635\n",
      "[317]\tvalid_0's auc: 0.545656\n",
      "[318]\tvalid_0's auc: 0.545639\n",
      "[319]\tvalid_0's auc: 0.545651\n",
      "[320]\tvalid_0's auc: 0.545688\n",
      "[321]\tvalid_0's auc: 0.545682\n",
      "[322]\tvalid_0's auc: 0.545713\n",
      "[323]\tvalid_0's auc: 0.545698\n",
      "[324]\tvalid_0's auc: 0.545721\n",
      "[325]\tvalid_0's auc: 0.545785\n",
      "[326]\tvalid_0's auc: 0.545749\n",
      "[327]\tvalid_0's auc: 0.545759\n",
      "[328]\tvalid_0's auc: 0.545775\n",
      "[329]\tvalid_0's auc: 0.54576\n",
      "[330]\tvalid_0's auc: 0.545746\n",
      "[331]\tvalid_0's auc: 0.545725\n",
      "[332]\tvalid_0's auc: 0.545739\n",
      "[333]\tvalid_0's auc: 0.545766\n",
      "[334]\tvalid_0's auc: 0.545802\n",
      "[335]\tvalid_0's auc: 0.545841\n",
      "[336]\tvalid_0's auc: 0.545883\n",
      "[337]\tvalid_0's auc: 0.545925\n",
      "[338]\tvalid_0's auc: 0.545974\n",
      "[339]\tvalid_0's auc: 0.546033\n",
      "[340]\tvalid_0's auc: 0.546019\n",
      "[341]\tvalid_0's auc: 0.546038\n",
      "[342]\tvalid_0's auc: 0.546104\n",
      "[343]\tvalid_0's auc: 0.546098\n",
      "[344]\tvalid_0's auc: 0.546085\n",
      "[345]\tvalid_0's auc: 0.546057\n",
      "[346]\tvalid_0's auc: 0.54609\n",
      "[347]\tvalid_0's auc: 0.54607\n",
      "[348]\tvalid_0's auc: 0.546099\n",
      "[349]\tvalid_0's auc: 0.546111\n",
      "[350]\tvalid_0's auc: 0.546088\n",
      "[351]\tvalid_0's auc: 0.5461\n",
      "[352]\tvalid_0's auc: 0.546121\n",
      "[353]\tvalid_0's auc: 0.546161\n",
      "[354]\tvalid_0's auc: 0.546116\n",
      "[355]\tvalid_0's auc: 0.546164\n",
      "[356]\tvalid_0's auc: 0.546162\n",
      "[357]\tvalid_0's auc: 0.546146\n",
      "[358]\tvalid_0's auc: 0.546212\n",
      "[359]\tvalid_0's auc: 0.546222\n",
      "[360]\tvalid_0's auc: 0.546214\n",
      "[361]\tvalid_0's auc: 0.546235\n",
      "[362]\tvalid_0's auc: 0.546257\n",
      "[363]\tvalid_0's auc: 0.546244\n",
      "[364]\tvalid_0's auc: 0.546312\n",
      "[365]\tvalid_0's auc: 0.546297\n",
      "[366]\tvalid_0's auc: 0.546309\n",
      "[367]\tvalid_0's auc: 0.54629\n",
      "[368]\tvalid_0's auc: 0.546328\n",
      "[369]\tvalid_0's auc: 0.546336\n",
      "[370]\tvalid_0's auc: 0.546372\n",
      "[371]\tvalid_0's auc: 0.546368\n",
      "[372]\tvalid_0's auc: 0.546389\n",
      "[373]\tvalid_0's auc: 0.546444\n",
      "[374]\tvalid_0's auc: 0.546478\n",
      "[375]\tvalid_0's auc: 0.546462\n",
      "[376]\tvalid_0's auc: 0.546492\n",
      "[377]\tvalid_0's auc: 0.546513\n",
      "[378]\tvalid_0's auc: 0.546529\n",
      "[379]\tvalid_0's auc: 0.546526\n",
      "[380]\tvalid_0's auc: 0.546522\n",
      "[381]\tvalid_0's auc: 0.54654\n",
      "[382]\tvalid_0's auc: 0.546565\n",
      "[383]\tvalid_0's auc: 0.54655\n",
      "[384]\tvalid_0's auc: 0.546571\n",
      "[385]\tvalid_0's auc: 0.546598\n",
      "[386]\tvalid_0's auc: 0.54663\n",
      "[387]\tvalid_0's auc: 0.546626\n",
      "[388]\tvalid_0's auc: 0.546627\n",
      "[389]\tvalid_0's auc: 0.546658\n",
      "[390]\tvalid_0's auc: 0.546697\n",
      "[391]\tvalid_0's auc: 0.546728\n",
      "[392]\tvalid_0's auc: 0.546706\n",
      "[393]\tvalid_0's auc: 0.54671\n",
      "[394]\tvalid_0's auc: 0.546724\n",
      "[395]\tvalid_0's auc: 0.546732\n",
      "[396]\tvalid_0's auc: 0.546801\n",
      "[397]\tvalid_0's auc: 0.546847\n",
      "[398]\tvalid_0's auc: 0.546867\n",
      "[399]\tvalid_0's auc: 0.546879\n",
      "[400]\tvalid_0's auc: 0.546919\n",
      "[401]\tvalid_0's auc: 0.546926\n",
      "[402]\tvalid_0's auc: 0.546954\n",
      "[403]\tvalid_0's auc: 0.546946\n",
      "[404]\tvalid_0's auc: 0.546945\n",
      "[405]\tvalid_0's auc: 0.546936\n",
      "[406]\tvalid_0's auc: 0.546935\n",
      "[407]\tvalid_0's auc: 0.546925\n",
      "[408]\tvalid_0's auc: 0.546928\n",
      "[409]\tvalid_0's auc: 0.546949\n",
      "[410]\tvalid_0's auc: 0.546955\n",
      "[411]\tvalid_0's auc: 0.546956\n",
      "[412]\tvalid_0's auc: 0.546914\n",
      "[413]\tvalid_0's auc: 0.546947\n",
      "[414]\tvalid_0's auc: 0.546971\n",
      "[415]\tvalid_0's auc: 0.547\n",
      "[416]\tvalid_0's auc: 0.546963\n",
      "[417]\tvalid_0's auc: 0.546966\n",
      "[418]\tvalid_0's auc: 0.546941\n",
      "[419]\tvalid_0's auc: 0.546967\n",
      "[420]\tvalid_0's auc: 0.546942\n",
      "[421]\tvalid_0's auc: 0.546978\n",
      "[422]\tvalid_0's auc: 0.546996\n",
      "[423]\tvalid_0's auc: 0.546994\n",
      "[424]\tvalid_0's auc: 0.54704\n",
      "[425]\tvalid_0's auc: 0.547062\n",
      "[426]\tvalid_0's auc: 0.547087\n",
      "[427]\tvalid_0's auc: 0.547113\n",
      "[428]\tvalid_0's auc: 0.547044\n",
      "[429]\tvalid_0's auc: 0.547083\n",
      "[430]\tvalid_0's auc: 0.547133\n",
      "[431]\tvalid_0's auc: 0.547138\n",
      "[432]\tvalid_0's auc: 0.547149\n",
      "[433]\tvalid_0's auc: 0.547169\n",
      "[434]\tvalid_0's auc: 0.547159\n",
      "[435]\tvalid_0's auc: 0.547212\n",
      "[436]\tvalid_0's auc: 0.547243\n",
      "[437]\tvalid_0's auc: 0.547249\n",
      "[438]\tvalid_0's auc: 0.547268\n",
      "[439]\tvalid_0's auc: 0.547297\n",
      "[440]\tvalid_0's auc: 0.54728\n",
      "[441]\tvalid_0's auc: 0.547288\n",
      "[442]\tvalid_0's auc: 0.54733\n",
      "[443]\tvalid_0's auc: 0.547339\n",
      "[444]\tvalid_0's auc: 0.547369\n",
      "[445]\tvalid_0's auc: 0.54738\n",
      "[446]\tvalid_0's auc: 0.54739\n",
      "[447]\tvalid_0's auc: 0.547435\n",
      "[448]\tvalid_0's auc: 0.547428\n",
      "[449]\tvalid_0's auc: 0.54748\n",
      "[450]\tvalid_0's auc: 0.547456\n",
      "[451]\tvalid_0's auc: 0.547467\n",
      "[452]\tvalid_0's auc: 0.54746\n",
      "[453]\tvalid_0's auc: 0.547515\n",
      "[454]\tvalid_0's auc: 0.547547\n",
      "[455]\tvalid_0's auc: 0.547517\n",
      "[456]\tvalid_0's auc: 0.547548\n",
      "[457]\tvalid_0's auc: 0.547544\n",
      "[458]\tvalid_0's auc: 0.54756\n",
      "[459]\tvalid_0's auc: 0.547589\n",
      "[460]\tvalid_0's auc: 0.547572\n",
      "[461]\tvalid_0's auc: 0.547617\n",
      "[462]\tvalid_0's auc: 0.547618\n",
      "[463]\tvalid_0's auc: 0.547625\n",
      "[464]\tvalid_0's auc: 0.547635\n",
      "[465]\tvalid_0's auc: 0.547607\n",
      "[466]\tvalid_0's auc: 0.547613\n",
      "[467]\tvalid_0's auc: 0.547637\n",
      "[468]\tvalid_0's auc: 0.547637\n",
      "[469]\tvalid_0's auc: 0.54765\n",
      "[470]\tvalid_0's auc: 0.547677\n",
      "[471]\tvalid_0's auc: 0.547699\n",
      "[472]\tvalid_0's auc: 0.547752\n",
      "[473]\tvalid_0's auc: 0.547761\n",
      "[474]\tvalid_0's auc: 0.547739\n",
      "[475]\tvalid_0's auc: 0.547757\n",
      "[476]\tvalid_0's auc: 0.547764\n",
      "[477]\tvalid_0's auc: 0.547792\n",
      "[478]\tvalid_0's auc: 0.547812\n",
      "[479]\tvalid_0's auc: 0.54784\n",
      "[480]\tvalid_0's auc: 0.54787\n",
      "[481]\tvalid_0's auc: 0.547895\n",
      "[482]\tvalid_0's auc: 0.547926\n",
      "[483]\tvalid_0's auc: 0.547948\n",
      "[484]\tvalid_0's auc: 0.54797\n",
      "[485]\tvalid_0's auc: 0.547986\n",
      "[486]\tvalid_0's auc: 0.548019\n",
      "[487]\tvalid_0's auc: 0.548034\n",
      "[488]\tvalid_0's auc: 0.548028\n",
      "[489]\tvalid_0's auc: 0.548096\n",
      "[490]\tvalid_0's auc: 0.548092\n",
      "[491]\tvalid_0's auc: 0.548104\n",
      "[492]\tvalid_0's auc: 0.548098\n",
      "[493]\tvalid_0's auc: 0.548146\n",
      "[494]\tvalid_0's auc: 0.548175\n",
      "[495]\tvalid_0's auc: 0.54821\n",
      "[496]\tvalid_0's auc: 0.548222\n",
      "[497]\tvalid_0's auc: 0.548198\n",
      "[498]\tvalid_0's auc: 0.548221\n",
      "[499]\tvalid_0's auc: 0.548224\n",
      "[500]\tvalid_0's auc: 0.548224\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's auc: 0.548224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caijiayue\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:447: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "def LGB_predict(train_x,train_y,test_x,res):\n",
    "    print(\"LGB test\")\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,zero_as_missing=True,\n",
    "        max_depth=-1, n_estimators=500, objective='binary',\n",
    "        subsample=0.9, colsample_bytree=0.8, subsample_freq=1,\n",
    "        learning_rate=0.1, min_child_weight=50, random_state=2018, n_jobs=100\n",
    "    )\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y)], eval_metric='auc',early_stopping_rounds=100)\n",
    "    res['score'] = clf.predict_proba(test_x)[:,1]\n",
    "    res['score'] = res['score'].apply(lambda x: float('%.6f' % x))\n",
    "    res.to_csv('../data/submission.csv', index=False)\n",
    "    os.system('zip baseline.zip ../data/submission.csv')\n",
    "    return clf\n",
    "\n",
    "model=LGB_predict(train_x,train_y,test_x,res)\n",
    "#baselineTIAOCAN [497]\tvalid_0's auc: 0.537973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
