{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer#,TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from scipy import sparse\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fit(train, clf):\n",
    "    one_hot_feature=['LBS','age','carrier','consumptionAbility','education','gender','house']\n",
    "    vector_feature=['appIdAction','appIdInstall','marriageStatus','interest1','interest2','interest3','interest4','interest5','kw1','kw2','kw3','topic1','topic2','topic3']\n",
    "    \n",
    "    #LabelEncoder将各种标签分配一个可数的连续编号\n",
    "    for feature in one_hot_feature:\n",
    "        try:\n",
    "            data[feature] = LabelEncoder().fit_transform(data[feature].apply(int))\n",
    "        except:\n",
    "            data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "            \n",
    "    #划分训练集、测试集\n",
    "    train=data[data.label!=-1]\n",
    "    train_y=train.pop('label')\n",
    "\n",
    "    train_x=train[['advertiserId','campaignId', 'creativeId','creativeSize','adCategoryId', 'productId','productType']]\n",
    "                  # ,'ct_0','ct_1','ct_2','ct_3','ct_4','os_0','os_1','os_2']]\n",
    "                  # ,'has_appins','has_appact','max_marriageStatus']]\n",
    "            \n",
    "    #one-hot特征reshape\n",
    "    enc = OneHotEncoder()\n",
    "    for feature in one_hot_feature:\n",
    "        enc.fit(train[feature].values.reshape(-1, 1))\n",
    "        train_a=enc.transform(train[feature].values.reshape(-1, 1))\n",
    "        train_x= sparse.hstack((train_x, train_a))\n",
    "    print('one-hot prepared !')\n",
    "    del train_a\n",
    "\n",
    "    #向量特征reshape\n",
    "    cv=CountVectorizer(ngram_range=(1, 2),token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "    for feature in vector_feature:\n",
    "        cv.fit(train[feature])\n",
    "        train_a = cv.transform(train[feature])\n",
    "        train_x = sparse.hstack((train_x, train_a))\n",
    "    print('cv prepared !')\n",
    "    del train_a\n",
    "    \n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y)], eval_metric='auc',early_stopping_rounds=100)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(test, clf):\n",
    "    one_hot_feature=['LBS','age','carrier','consumptionAbility','education','gender','house']\n",
    "    vector_feature=['appIdAction','appIdInstall','marriageStatus','interest1','interest2','interest3','interest4','interest5','kw1','kw2','kw3','topic1','topic2','topic3']\n",
    "\n",
    "    #LabelEncoder将各种标签分配一个可数的连续编号\n",
    "    for feature in one_hot_feature:\n",
    "        try:\n",
    "            data[feature] = LabelEncoder().fit_transform(data[feature].apply(int))\n",
    "        except:\n",
    "            data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "    test=data[data.label==-1]\n",
    "    res=test[['aid','uid']]\n",
    "    test=test.drop('label',axis=1)\n",
    "\n",
    "    test_x = test[['advertiserId','campaignId', 'creativeId','creativeSize','adCategoryId', 'productId', 'productType']]\n",
    "                # ,'ct_0','ct_1','ct_2','ct_3','ct_4','os_0','os_1','os_2']]\n",
    "                ##,'has_appins','has_appact','max_marriageStatus']]\n",
    "\n",
    "    #one-hot特征reshape\n",
    "    enc = OneHotEncoder()\n",
    "    for feature in one_hot_feature:\n",
    "        enc.fit(test[feature].values.reshape(-1, 1))\n",
    "        test_a = enc.transform(test[feature].values.reshape(-1, 1))\n",
    "        test_x = sparse.hstack((test_x, test_a))\n",
    "    print('one-hot prepared !')\n",
    "    del test_a\n",
    "    \n",
    "    ##向量特征reshape\n",
    "    cv=CountVectorizer(ngram_range=(1, 2),token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "    for feature in vector_feature:\n",
    "        cv.fit(test[feature])\n",
    "        test_a = cv.transform(test[feature])\n",
    "        test_x = sparse.hstack((test_x, test_a))\n",
    "    print('cv prepared !')\n",
    "    del test_a\n",
    "\n",
    "    return test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFile(filename, num):\n",
    "    for i in range(1,num+1):\n",
    "        try:\n",
    "            load_filename = 'data1/submission/submission_%d.csv'%i\n",
    "            fin = open(load_filename,'r')\n",
    "            fout = open(filename,'a')\n",
    "            head = fin.readline()\n",
    "            if i == 1:\n",
    "                fout.writelines([head])\n",
    "            buf = []\n",
    "            for line in fin:\n",
    "                buf.append(line)\n",
    "            fout.writelines(buf)\n",
    "        finally:\n",
    "            fin.close()\n",
    "            fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data1/'\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,zero_as_missing=True,\n",
    "    max_depth=-1, n_estimators=2000, objective='binary',\n",
    "    subsample=0.9, colsample_bytree=0.8, subsample_freq=1,\n",
    "    learning_rate=0.2, min_child_weight=50, random_state=2018, n_jobs=100\n",
    ")\n",
    "\n",
    "s_1 = time.time()\n",
    "\n",
    "train=pd.read_csv(path+'train.csv')\n",
    "train=train[train.label!=-1]\n",
    "train=train.fillna('-1')\n",
    "\n",
    "clf=train_fit(train, clf)\n",
    "\n",
    "s_2 = time.time()\n",
    "print(\"LGB: train fit OK!\")\n",
    "print('train use time : %d'%(s_2-s_1))\n",
    "\n",
    "beg = 1\n",
    "end = 12      # test切分的份数\n",
    "\n",
    "for i in range(beg,end+1):  \n",
    "    s_1 = time.time()\n",
    "    test=pd.read_csv('%s/test/test_%d.csv'%(path,i)\n",
    "    test['label'] = -1\n",
    "    test=test.fillna('-1')\n",
    "    \n",
    "    test_x=predict_test(test, clf)\n",
    "\n",
    "    res['score'] = clf.predict_proba(test_x)[:,1]\n",
    "    res['score'] = res['score'].apply(lambda x: float('%.6f' % x))\n",
    "    res.to_csv('%s/submission_%d.csv'%(path,i), index=False)\n",
    "    print(\"LGB: test_%d is OK!\")\n",
    "\n",
    "    s_2 = time.time()\n",
    "    print('test_%d use time : %d'%(i,(s_2-s_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12\n",
    "combineFile('data1/submission.csv',N)\n",
    "print('LGB baseline is OK!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
