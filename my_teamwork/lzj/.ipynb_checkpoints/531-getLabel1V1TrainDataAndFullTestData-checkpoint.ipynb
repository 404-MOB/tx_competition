{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "train_name = 'train'\n",
    "ad_feature_name = 'adFeature'\n",
    "user_feature_name = 'userFeature'\n",
    "test_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('%s/%s.csv'%(path,train_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_T = train[train.label == 1]\n",
    "train_label_F = train[train.label == -1]\n",
    "label_T_num = len(train_label_T)\n",
    "label_F_num = len(train_label_F)\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_T.to_csv('%s/%s.csv'%(path,'train_label_T'),index=False)\n",
    "train_label_F.to_csv('%s/%s.csv'%(path,'train_label_F'),index=False)\n",
    "del train_label_T\n",
    "del train_label_F\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkSubFile(lines, head, srcName, sub):\n",
    "    [des_filename, extname] = os.path.splitext(srcName)\n",
    "    filename = des_filename + '_' + str(sub) + extname\n",
    "    print('make file: %s' % filename)\n",
    "    fout = open(filename, 'w')\n",
    "    try:\n",
    "        fout.writelines([head])\n",
    "        fout.writelines(lines)\n",
    "        return sub + 1\n",
    "    finally:\n",
    "        fout.close()\n",
    "def splitByLineCount(filename, count):\n",
    "    fin = open(filename, 'r')\n",
    "    try:\n",
    "        head = fin.readline()\n",
    "        buf = []\n",
    "        sub = 1\n",
    "        for line in fin:\n",
    "            buf.append(line)\n",
    "            if len(buf) == count:\n",
    "                sub = mkSubFile(buf, head, filename, sub)\n",
    "                buf = []\n",
    "        if len(buf) != 0:\n",
    "            sub = mkSubFile(buf, head, filename, sub)\n",
    "    finally:\n",
    "        fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make file: data/train_label_F_1.csv\n",
      "make file: data/train_label_F_2.csv\n",
      "make file: data/train_label_F_3.csv\n",
      "make file: data/train_label_F_4.csv\n",
      "make file: data/train_label_F_5.csv\n",
      "make file: data/train_label_F_6.csv\n",
      "make file: data/train_label_F_7.csv\n",
      "make file: data/train_label_F_8.csv\n",
      "make file: data/train_label_F_9.csv\n",
      "make file: data/train_label_F_10.csv\n",
      "make file: data/train_label_F_11.csv\n",
      "make file: data/train_label_F_12.csv\n",
      "make file: data/train_label_F_13.csv\n",
      "make file: data/train_label_F_14.csv\n",
      "make file: data/train_label_F_15.csv\n",
      "make file: data/train_label_F_16.csv\n",
      "make file: data/train_label_F_17.csv\n",
      "make file: data/train_label_F_18.csv\n",
      "make file: data/train_label_F_19.csv\n",
      "make file: data/train_label_F_20.csv\n",
      "make file: data/test_1.csv\n",
      "make file: data/test_2.csv\n",
      "make file: data/test_3.csv\n"
     ]
    }
   ],
   "source": [
    "splitByLineCount('%s/%s.csv'%(path,'train_label_F'),label_T_num)\n",
    "splitByLineCount('data/test.csv',label_T_num*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/test.csv'):\n",
    "    os.remove('data/test.csv')\n",
    "if os.path.exists('data/train.csv'):\n",
    "    os.remove('data/train.csv')\n",
    "if os.path.exists('%s/%s.csv'%(path,'train_label_F')):\n",
    "    os.remove('%s/%s.csv'%(path,'train_label_F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "train_F_name = 'train_label_F_1'   # 选取label_0所有切分子文件的第一个\n",
    "train_T_name = 'train_label_T'\n",
    "ad_feature_name = 'adFeature'\n",
    "user_feature_name = 'userFeature'\n",
    "test_name = 'test'\n",
    "data_name = 'train_label_TF_1V1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_F = pd.read_csv('%s/%s.csv'%(path,train_F_name))\n",
    "train_T = pd.read_csv('%s/%s.csv'%(path,train_T_name))\n",
    "data = pd.concat([train_F,train_T],ignore_index=True)\n",
    "del train_F\n",
    "del train_T\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_csv('%s/%s.csv'%(path,data_name),index=False)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('%s/%s.csv'%(path,train_T_name)):\n",
    "    os.remove('%s/%s.csv'%(path,train_T_name))\n",
    "for i in range(1,99):\n",
    "    if os.path.exists('%s/%s_%d.csv'%(path,'train_label_F',i)):\n",
    "        os.remove('%s/%s_%d.csv'%(path,'train_label_F',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_train_full_data(path,ad_feature_name,user_feature_name,train_name,data_name):\n",
    "    count = 111\n",
    "    num = 0;\n",
    "    for i in range(1,count+1):\n",
    "#         time1 = time.time()\n",
    "        n = getTrainData(path,ad_feature_name,user_feature_name+'_'+str(i),train_name,data_name+'_'+str(i))\n",
    "        print(n)\n",
    "        num += n\n",
    "    print('total:%d'%num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainData(path,ad_feature_name,user_feature_name,train_name,data_name):\n",
    "    ad_feature = pd.read_csv(path+'/'+ad_feature_name+'.csv')\n",
    "    user_feature = pd.read_csv(path+'/userFeature/'+user_feature_name+'.csv')\n",
    "    train = pd.read_csv(path+'/'+train_name+'.csv')\n",
    "    user_feature = user_feature.fillna(-1)\n",
    "    \n",
    "    data = pd.merge(train,ad_feature,on='aid',how='left')\n",
    "    data = pd.merge(data,user_feature,on='uid',how='left')\n",
    "    data = (data[data.house >= -1])\n",
    "    \n",
    "    n = len(data)\n",
    "    if os.path.isdir(path+'/TF_1V1_train') is False:\n",
    "        os.makedirs(path+'/TF_1V1_train')\n",
    "    data.to_csv(path+'/TF_1V1_train/'+data_name+'.csv',index=False)\n",
    "    \n",
    "    del ad_feature\n",
    "    del user_feature\n",
    "    del train\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "ad_feature_name = 'adFeature'\n",
    "user_feature_name = 'userFeature'\n",
    "train_name = 'train_label_TF_1V1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39422\n",
      "39053\n",
      "39039\n",
      "39449\n",
      "39349\n",
      "39316\n",
      "39003\n",
      "39218\n",
      "39679\n",
      "39467\n",
      "39269\n",
      "39398\n",
      "39490\n",
      "39397\n",
      "39527\n",
      "39460\n",
      "39462\n",
      "39499\n",
      "39554\n",
      "39310\n",
      "39331\n",
      "39903\n",
      "39777\n",
      "39253\n",
      "39774\n",
      "39073\n",
      "39426\n",
      "38673\n",
      "39169\n",
      "39329\n",
      "39178\n",
      "39342\n",
      "39261\n",
      "39233\n",
      "39467\n",
      "39372\n",
      "39381\n",
      "39421\n",
      "39424\n",
      "39444\n",
      "39331\n",
      "39610\n",
      "39499\n",
      "39234\n",
      "39633\n",
      "39799\n",
      "39548\n",
      "39504\n",
      "39544\n",
      "39567\n",
      "39369\n",
      "39594\n",
      "39774\n",
      "39222\n",
      "39567\n",
      "39921\n",
      "39411\n",
      "39589\n",
      "39572\n",
      "39469\n",
      "39163\n",
      "39581\n",
      "39723\n",
      "39437\n",
      "39164\n",
      "39534\n",
      "39673\n",
      "38745\n",
      "39503\n",
      "39673\n",
      "39230\n",
      "39703\n",
      "39642\n",
      "39178\n",
      "39645\n",
      "39486\n",
      "39490\n",
      "39509\n",
      "39446\n",
      "39122\n",
      "39377\n",
      "39414\n",
      "39140\n",
      "39303\n",
      "39787\n",
      "38862\n",
      "39312\n",
      "39413\n",
      "39595\n",
      "38906\n",
      "39696\n",
      "38995\n",
      "39372\n",
      "39269\n",
      "39157\n",
      "39005\n",
      "39219\n",
      "39961\n",
      "40224\n",
      "39429\n",
      "39952\n",
      "39184\n",
      "39358\n",
      "39422\n",
      "39468\n",
      "39561\n",
      "39394\n",
      "39405\n",
      "38977\n",
      "39295\n",
      "29358\n",
      "total:4364806\n",
      "train_label_TF_1V1 merge userFeature totally use time:1826's\n"
     ]
    }
   ],
   "source": [
    "s_1 = time.time()\n",
    "get_one_train_full_data(path,ad_feature_name,user_feature_name,train_name,train_name)\n",
    "s_2 = time.time()\n",
    "print('%s merge %s totally use time:%d\\'s'%(train_name,user_feature_name,(s_2-s_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFile(filename, num):\n",
    "    for i in range(1,num+1):\n",
    "        try:\n",
    "            load_filename = 'data/TF_1V1_train/train_label_TF_1V1_%d.csv'%i\n",
    "            fin = open(load_filename,'r')\n",
    "            fout = open(filename,'a')\n",
    "            head = fin.readline()\n",
    "            if i == 1:\n",
    "                fout.writelines([head])\n",
    "            buf = []\n",
    "            for line in fin:\n",
    "                buf.append(line)\n",
    "            fout.writelines(buf)\n",
    "        finally:\n",
    "            fin.close()\n",
    "            fout.close()\n",
    "            if os.path.exists(load_filename):\n",
    "                os.remove(load_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineFile('data/TF_1V1_train/full_merge_train_TF_1V1.csv',111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/train_label_TF_1V1.csv'):\n",
    "    os.remove('data/train_label_TF_1V1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "ad_feature_name = 'adFeature'\n",
    "user_feature_name = 'userFeature'\n",
    "test_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_test_full_data(path,ad_feature_name,user_feature_name,test_name,data_name):\n",
    "    count = 111\n",
    "    num = 0;\n",
    "    for i in range(1,count+1):\n",
    "#         time1 = time.time()\n",
    "        n = getTestData(path,ad_feature_name,user_feature_name+'_'+str(i),test_name,data_name+'_'+str(i))\n",
    "        print(n)\n",
    "        num += n\n",
    "    print('total:%d'%num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestData(path,ad_feature_name,user_feature_name,test_name,data_name):\n",
    "    ad_feature = pd.read_csv(path+'/'+ad_feature_name+'.csv')\n",
    "    user_feature = pd.read_csv(path+'/userFeature/'+user_feature_name+'.csv')\n",
    "    test = pd.read_csv(path+'/'+test_name+'.csv')\n",
    "    user_feature = user_feature.fillna(-1)\n",
    "    \n",
    "    data = pd.merge(test,ad_feature,on='aid',how='left')\n",
    "    data = pd.merge(data,user_feature,on='uid',how='left')\n",
    "    data = (data[data.house >= -1])\n",
    "    \n",
    "    n = len(data)\n",
    "    if os.path.isdir(path+'/test') is False:\n",
    "        os.makedirs(path+'/test')\n",
    "    data.to_csv(path+'/test/'+data_name+'.csv',index=False)\n",
    "    \n",
    "    del ad_feature\n",
    "    del user_feature\n",
    "    del test\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFile(filename, num):\n",
    "    [des_filename, extname] = os.path.splitext(filename)\n",
    "    for i in range(1,num+1):\n",
    "        try:\n",
    "            load_filename = '%s_%d%s'%(des_filename,i,extname)\n",
    "            fin = open(load_filename,'r')\n",
    "            fout = open(filename,'a')\n",
    "            head = fin.readline()\n",
    "            if i == 1:\n",
    "                fout.writelines([head])\n",
    "            buf = []\n",
    "            for line in fin:\n",
    "                buf.append(line)\n",
    "            fout.writelines(buf)\n",
    "        finally:\n",
    "            fin.close()\n",
    "            fout.close()\n",
    "            if os.path.exists(load_filename):\n",
    "                os.remove(load_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39343\n",
      "39239\n",
      "39178\n",
      "39202\n",
      "39285\n",
      "39028\n",
      "39544\n",
      "39507\n",
      "39333\n",
      "39287\n",
      "39222\n",
      "39460\n",
      "39371\n",
      "38790\n",
      "39823\n",
      "39501\n",
      "39509\n",
      "39673\n",
      "39530\n",
      "39008\n",
      "39500\n",
      "39836\n",
      "39426\n",
      "39032\n",
      "38931\n",
      "39384\n",
      "39356\n",
      "39538\n",
      "39302\n",
      "39778\n",
      "39547\n",
      "39289\n",
      "39144\n",
      "39509\n",
      "39294\n",
      "39693\n",
      "39694\n",
      "39278\n",
      "39696\n",
      "39549\n",
      "39767\n",
      "39234\n",
      "39530\n",
      "39247\n",
      "39503\n",
      "39342\n",
      "39411\n",
      "39223\n",
      "39334\n",
      "39437\n",
      "39479\n",
      "39542\n",
      "39442\n",
      "39562\n",
      "39359\n",
      "39728\n",
      "39576\n",
      "39128\n",
      "39401\n",
      "39435\n",
      "39343\n",
      "39442\n",
      "39242\n",
      "39566\n",
      "39325\n",
      "39580\n",
      "39353\n",
      "39899\n",
      "39299\n",
      "39647\n",
      "39245\n",
      "39338\n",
      "39162\n",
      "39475\n",
      "39258\n",
      "39327\n",
      "39594\n",
      "39661\n",
      "39368\n",
      "39407\n",
      "39370\n",
      "39551\n",
      "39174\n",
      "39478\n",
      "39104\n",
      "39197\n",
      "39283\n",
      "39209\n",
      "39602\n",
      "39222\n",
      "39768\n",
      "39547\n",
      "39442\n",
      "39504\n",
      "39794\n",
      "39321\n",
      "39436\n",
      "39443\n",
      "39846\n",
      "39408\n",
      "39832\n",
      "39490\n",
      "39492\n",
      "39346\n",
      "39157\n",
      "39295\n",
      "39488\n",
      "39644\n",
      "39221\n",
      "39323\n",
      "28999\n",
      "total:4364806\n",
      "test_1 merge userFeature totally use time:1412's\n",
      "39611\n",
      "39355\n",
      "39567\n",
      "39319\n",
      "39691\n",
      "39305\n",
      "39519\n",
      "39545\n",
      "39454\n",
      "39551\n",
      "39327\n",
      "39079\n",
      "39243\n",
      "39452\n",
      "39176\n",
      "40006\n",
      "39432\n",
      "39347\n",
      "38838\n",
      "39720\n",
      "39483\n",
      "39734\n",
      "39394\n",
      "39775\n",
      "39467\n",
      "39272\n",
      "39778\n",
      "39320\n",
      "39554\n",
      "39418\n",
      "39406\n",
      "39256\n",
      "39470\n",
      "39401\n",
      "39621\n",
      "39637\n",
      "39394\n",
      "39623\n",
      "39634\n",
      "39493\n",
      "39502\n",
      "39852\n",
      "38820\n",
      "39471\n",
      "39216\n",
      "39413\n",
      "39836\n",
      "39526\n",
      "39584\n",
      "39333\n",
      "39579\n",
      "39663\n",
      "39360\n",
      "39584\n",
      "39384\n",
      "39509\n",
      "39256\n",
      "39270\n",
      "39542\n",
      "39306\n",
      "39262\n",
      "39699\n",
      "39727\n",
      "39166\n",
      "39439\n",
      "39450\n",
      "39340\n",
      "39197\n",
      "39176\n",
      "39239\n",
      "39190\n",
      "39441\n",
      "39290\n",
      "39415\n",
      "39263\n",
      "39467\n",
      "39285\n",
      "39280\n",
      "39266\n",
      "39402\n",
      "39088\n",
      "39470\n",
      "39176\n",
      "39365\n",
      "39322\n",
      "39240\n",
      "39794\n",
      "39155\n",
      "39221\n",
      "39646\n",
      "39163\n",
      "39390\n",
      "39542\n",
      "39890\n",
      "39425\n",
      "39445\n",
      "39120\n",
      "39252\n",
      "39238\n",
      "39219\n",
      "39161\n",
      "39538\n",
      "39249\n",
      "39522\n",
      "39414\n",
      "38995\n",
      "39647\n",
      "39719\n",
      "39368\n",
      "39441\n",
      "28924\n",
      "total:4364806\n",
      "test_2 merge userFeature totally use time:1414's\n",
      "26896\n",
      "27194\n",
      "27209\n",
      "27090\n",
      "27055\n",
      "26776\n",
      "27045\n",
      "27069\n",
      "26809\n",
      "27126\n",
      "27178\n",
      "27015\n",
      "27288\n",
      "27342\n",
      "26996\n",
      "26907\n",
      "27000\n",
      "26959\n",
      "27157\n",
      "27238\n",
      "27202\n",
      "27219\n",
      "27193\n",
      "27295\n",
      "27293\n",
      "27184\n",
      "26792\n",
      "27105\n",
      "26993\n",
      "27153\n",
      "27310\n",
      "27120\n",
      "26996\n",
      "27109\n",
      "27009\n",
      "26951\n",
      "26865\n",
      "27402\n",
      "27110\n",
      "26883\n",
      "27213\n",
      "27360\n",
      "27271\n",
      "26901\n",
      "27205\n",
      "27125\n",
      "27299\n",
      "26993\n",
      "26961\n",
      "27138\n",
      "27330\n",
      "26892\n",
      "27104\n",
      "27281\n",
      "27133\n",
      "27120\n",
      "27346\n",
      "27079\n",
      "26940\n",
      "27046\n",
      "26988\n",
      "26946\n",
      "26948\n",
      "26751\n",
      "26953\n",
      "27340\n",
      "27131\n",
      "27038\n",
      "26960\n",
      "27040\n",
      "27100\n",
      "26869\n",
      "27276\n",
      "27236\n",
      "27010\n",
      "26877\n",
      "27455\n",
      "27064\n",
      "26970\n",
      "27134\n",
      "27405\n",
      "27234\n",
      "27294\n",
      "27099\n",
      "26882\n",
      "26807\n",
      "26670\n",
      "27376\n",
      "27021\n",
      "27016\n",
      "26728\n",
      "26800\n",
      "27175\n",
      "26971\n",
      "26899\n",
      "27288\n",
      "27010\n",
      "27177\n",
      "27207\n",
      "27073\n",
      "26906\n",
      "27187\n",
      "27205\n",
      "27209\n",
      "26938\n",
      "27012\n",
      "26984\n",
      "27137\n",
      "27237\n",
      "27297\n",
      "19861\n",
      "total:2999461\n",
      "test_3 merge userFeature totally use time:1100's\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    s_1 = time.time()\n",
    "    get_one_test_full_data(path,ad_feature_name,user_feature_name,'%s_%d'%(test_name,i),'%s_%d'%(test_name,i))\n",
    "    s_2 = time.time()\n",
    "    print('%s merge %s totally use time:%d\\'s'%('%s_%d'%(test_name,i),user_feature_name,(s_2-s_1)))\n",
    "    os.remove('%s/%s_%d.csv'%(path,test_name,i))\n",
    "    combineFile('data/test/%s_%d.csv'%(test_name,i),111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineFile('data/test/%s.csv'%(test_name),3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
