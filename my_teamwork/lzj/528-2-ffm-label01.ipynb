{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明\n",
    "* 对1得到的label1:1完整数据集转换ffm\n",
    "* 输入目录\n",
    "\n",
    "path = 'data1'         # 为了方便不和前两个文件夹冲突,在同级目录创建data1,专门存放数据转换好以后用来预测的数据文件\n",
    "\n",
    "train_name = 'data.csv'      # 1之后得到的label 1:1 数据集   应该是在data/01data/里面\n",
    "\n",
    "test_name = 'test.csv'        # 测试集文件,要求是merge以后的文件\n",
    "\n",
    "train_temp_name = 'train_data.csv'   # ffm转换后的临时文件\n",
    "\n",
    "train_ffm_name = 'train_ffm.csv'      # ffm输入的训练集文件\n",
    "\n",
    "test_ffm_name = 'test_ffm.csv'       #  ffm输入的测试集文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import get_dummies\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import xlearn as xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMFormat:\n",
    "    def __init__(self,vector_feat,one_hot_feat,continus_feat):\n",
    "        self.field_index_ = None\n",
    "        self.feature_index_ = None\n",
    "        self.vector_feat=vector_feat\n",
    "        self.one_hot_feat=one_hot_feat\n",
    "        self.continus_feat=continus_feat\n",
    "        \n",
    "    def get_params(self):\n",
    "        pass\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        pass\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        self.field_index_ = {col: i for i, col in enumerate(df.columns)}\n",
    "        self.feature_index_ = dict()\n",
    "        last_idx = 0\n",
    "        for col in df.columns:\n",
    "            if col in self.one_hot_feat:\n",
    "                print(col)\n",
    "                df[col]=df[col].astype('int')\n",
    "                vals = np.unique(df[col])\n",
    "                for val in vals:\n",
    "                    if val==-1: continue\n",
    "                    name = '{}_{}'.format(col, val)\n",
    "                    if name not in self.feature_index_:\n",
    "                        self.feature_index_[name] = last_idx\n",
    "                        last_idx += 1\n",
    "            elif col in self.vector_feat:\n",
    "                print(col)\n",
    "                vals=[]\n",
    "                for data in df[col].apply(str):\n",
    "                    if data!=\"-1\":\n",
    "                        for word in data.strip().split(' '):\n",
    "                            vals.append(word)\n",
    "                vals = np.unique(vals)\n",
    "                for val in vals:\n",
    "                    if val==\"-1\": continue\n",
    "                    name = '{}_{}'.format(col, val)\n",
    "                    if name not in self.feature_index_:\n",
    "                        self.feature_index_[name] = last_idx\n",
    "                        last_idx += 1\n",
    "            self.feature_index_[col] = last_idx\n",
    "            last_idx += 1\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, df, y=None):\n",
    "        self.fit(df, y)\n",
    "        return self.transform(df)\n",
    "\n",
    "    def transform_row_(self, row):\n",
    "        ffm = []\n",
    "\n",
    "        for col, val in row.loc[row != 0].to_dict().items():\n",
    "            if col in self.one_hot_feat:\n",
    "                name = '{}_{}'.format(col, val)\n",
    "                if name in self.feature_index_:\n",
    "                    ffm.append('{}:{}:1'.format(self.field_index_[col], self.feature_index_[name]))\n",
    "                # ffm.append('{}:{}:{}'.format(self.field_index_[col], self.feature_index_[col], 1))\n",
    "            elif col in self.vector_feat:\n",
    "                for word in str(val).split(' '):\n",
    "                    name = '{}_{}'.format(col, word)\n",
    "                    if name in self.feature_index_:\n",
    "                        ffm.append('{}:{}:1'.format(self.field_index_[col], self.feature_index_[name]))\n",
    "            elif col in self.continus_feat:\n",
    "                if val!=-1:\n",
    "                    ffm.append('{}:{}:{}'.format(self.field_index_[col], self.feature_index_[col], val))\n",
    "        return ' '.join(ffm)\n",
    "\n",
    "    def transform(self, df):\n",
    "        # val=[]\n",
    "        # for k,v in self.feature_index_.items():\n",
    "        #     val.append(v)\n",
    "        # val.sort()\n",
    "        # print(val)\n",
    "        # print(self.field_index_)\n",
    "        # print(self.feature_index_)\n",
    "        return pd.Series({idx: self.transform_row_(row) for idx, row in df.iterrows()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_feature=['LBS','age','carrier','consumptionAbility','education','gender','advertiserId','campaignId', 'creativeId',\n",
    "       'adCategoryId', 'productId', 'productType']\n",
    "vector_feature=['interest1','interest2','interest5','kw1','kw2','topic1','topic2','os','ct','marriageStatus']\n",
    "continus_feature=['creativeSize']\n",
    "\n",
    "path = 'data1'\n",
    "train_name = 'data.csv'\n",
    "test_name = 'test.csv'\n",
    "train_temp_name = 'train_data.csv'\n",
    "train_ffm_name = 'train_ffm.csv'\n",
    "test_ffm_name = 'test_ffm.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBS\n",
      "age\n",
      "carrier\n",
      "consumptionAbility\n",
      "education\n",
      "gender\n",
      "advertiserId\n",
      "campaignId\n",
      "creativeId\n",
      "adCategoryId\n",
      "productId\n",
      "productType\n",
      "interest1\n",
      "interest2\n",
      "interest5\n",
      "kw1\n",
      "kw2\n",
      "topic1\n",
      "topic2\n",
      "os\n",
      "ct\n",
      "marriageStatus\n",
      "advertiserId\n",
      "campaignId\n",
      "creativeId\n",
      "adCategoryId\n",
      "productId\n",
      "productType\n",
      "LBS\n",
      "age\n",
      "carrier\n",
      "consumptionAbility\n",
      "ct\n",
      "education\n",
      "gender\n",
      "interest1\n",
      "interest2\n",
      "interest5\n",
      "kw1\n",
      "kw2\n",
      "marriageStatus\n",
      "os\n",
      "topic1\n",
      "topic2\n"
     ]
    }
   ],
   "source": [
    "tr = FFMFormat(vector_feature,one_hot_feature,continus_feature)\n",
    "train = pd.read_csv(path+'/'+train_name)\n",
    "test = pd.read_csv(path+'/'+test_name)\n",
    "\n",
    "Y = np.array(train.pop('label'))\n",
    "len_train = len(train)\n",
    "\n",
    "train = train[one_hot_feature+vector_feature+continus_feature]\n",
    "# vali = train[one_hot_feature+vector_feature+continus_feature]\n",
    "\n",
    "tr = FFMFormat(vector_feature,one_hot_feature,continus_feature)\n",
    "train_ffm = tr.fit_transform(train)\n",
    "test_ffm = tr.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换成功，数据位置：data1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5764"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ffm.to_csv(path+'/'+test_ffm_name,index=False)\n",
    "train_ffm.to_csv(path+'/'+train_temp_name,index=False)\n",
    "\n",
    "with open(path+'/'+train_temp_name) as fin:\n",
    "    f_train_out = open(path+'/'+train_ffm_name,'w')\n",
    "    for (i,line) in enumerate(fin):\n",
    "        f_train_out.write(str(Y[i])+' '+line)\n",
    "    f_train_out.close()\n",
    "    print('转换成功，数据位置：'+path)\n",
    "\n",
    "del train\n",
    "del test\n",
    "del test_ffm\n",
    "del train_ffm\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明\n",
    "* 这个时候已经得到了train_ffm和test_ffm,接下来带入模型预测\n",
    "* 这部分只要数据转换完成了，是可以单独运行的，即如果是为了调参，单独运行这一部分就行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import get_dummies\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import xlearn as xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'data1'\n",
    "test_name = 'test.csv'\n",
    "train_ffm_name = 'train_ffm.csv'\n",
    "test_ffm_name = 'test_ffm.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit ok:data1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data1/submission/submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-47ca006cfc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"output.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/submission/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# for i in lam:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1576\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data1/submission/submission.csv'"
     ]
    }
   ],
   "source": [
    "param = {'task':'binary', 'lr':0.02, 'lambda':0.000001,'metric': 'auc','opt':'ftrl','epoch':2,'k':2,\n",
    "         'alpha': 1.5, 'beta': 1, 'lambda_1': 0.0, 'lambda_2': 0.0}\n",
    "# lam = [0.1,0.03,0.01,0.003,0.001,0.0003,0.0001,0.00003,0.00001,0.000003,0.000001]\n",
    "# lr = [1,0.3,0.1,0.03,0.01]\n",
    "\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(path+'/'+train_ffm_name)\n",
    "ffm_model.setTest(path+'/'+test_ffm_name)\n",
    "# ffm_model.cv(param)\n",
    "# ffm_model.setValidate(path+'/ffm/'+vali_ffm_name)\n",
    "ffm_model.setSigmoid()\n",
    "ffm_model.fit(param,path+\"/\"+\"model.out\")\n",
    "print('fit ok:'+path)\n",
    "ffm_model.predict(path+\"/\"+\"model.out\",path+\"/\"+\"output.txt\")\n",
    "sub = pd.DataFrame()\n",
    "test_df = pd.read_csv(path+'/'+test_name)\n",
    "sub['aid']=test_df['aid']\n",
    "sub['uid']=test_df['uid']\n",
    "sub['score'] = np.loadtxt(path+\"/\"+\"output.txt\")\n",
    "sub.to_csv(path+'/submission/'+'submission.csv',index=False)\n",
    "\n",
    "# for i in lam:\n",
    "#     for j in lr:\n",
    "#         param['lr'] = j\n",
    "#         param['lambda'] = i\n",
    "#         print(param)\n",
    "#         ffm_model.cv(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
